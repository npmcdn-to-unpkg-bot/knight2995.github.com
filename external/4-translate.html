<h4>MPEG-1 Audio</h4>
<p style="text-align: left;"> </p>
<p><strong>MPEG doc#: N7703</strong></p>
<p><strong>Date: October 2005</strong></p>
<p><strong>Authors: B. Grill, S. Quackenbush</strong></p>

<p> </p>
<p style="text-align: left;">MPEG-1 1또는 2 계층의 오디오 레이어는 32~448 kb/s 에서 동작하고 32, 44.1 그리고 48 kHz의 샘플링 주파수를 지원하는 일반적인 서브밴드 코드이다. 레이어 2는 128-256 kbit/s 의 일반적인 비트율에 있고 384 kb/s는 전문가의 어플리케이션을 위해 존재한다.</p>
<p style="text-align: left;">MPEG-1 의 1 과 2 계층의 레이어는 1- 또는 2- 채널의 오디오 컨텐츠의 지각적인 코더입니다.
계층 1은 낮은 복잡도의 디코딩과 인코딩을 요구하는 어플리케이션을 위해 설계되어 왔습니다.계층 2는 조금 더 높은 복잡도에서의 좀 더 높은 압축률을 제공합니다. MPEG-1 계층 1을 사용함으로써 복호후의 높은 오디오 퀄리티를 유지하면서 일반적으로 높은 퀄리티의 오디오 CD 데이터를 압축할 수 있다.  
계층 2 또한 계층 1의 비트스트림을 복호화 할 수 있다.</p>
<p style="text-align: left;">MPEG-1 계층 3 (or MP3) 은 음악신호에 대한 우수한 압축률을 제공하는 1- 또는 2- 채널의 개념적 오디오 코더이다. 계층 1과 계층 2와 비교해서 더 높은 압축 효율을 제공한다. 이것은 높은 퀄리티의 오디오 CD 데이터를 높은 퀄리티를 유지하면서 12배 압축할 수 있다. 일반적으로 MP3는 모노 또는 스테레오 음악 또는 다른 오디오 신호를 저장또는 전송을 포함하는 어플리케이션에 적합하다. 이에 맞게 구현되어 있기에 거의 모든 디지털 오디오 디바이스에서 장치재생이 항상 보장된다.</p>
<p style="text-align: left;">낮은 복잡도때문에 디코딩은 Cascaded 인코딩/디코딩과 전송 에러에 대해 강인함을 가져, MPEG-1 계층 II는 디지털 오디오 그리고 비디오 방송 어플리케이션에 사용된다. 또한 비디오 CD 뿐만 아니라 스튜디오의 다양한 어플리케이션에 사용된다.
</p>
<p style="text-align: left;">계층 3또는 mp3라 부르는 것은 인터넷을 통해 음악 저장 및 전송을 위해 가장 널리 사용되는 오디오 코딩 포맷이다.
MP3는 그것의 이름을 따 MP3 플레이어라 불리는 새로운 클래스를 만들어낸다. 이것은 거의 모든 CD와 DVD 플레이어 그리고 증가하는 카 스테레오 시스템에서 발견된다. 그리고 홈 네트워크 음악 서버와 같은 새로운 혁신적인 홈 스테레오장치에서도. 추가적으로 계층 3는 위성 디지털 오디오 방송 및 휴대전화에서 찾을 수 있다.</p>
<p style="text-align: left;">MPEG-1 계층 3은 32, 44.1 그리고 48 KhZ에서의 높은 샘플링을 위해 1992년 MPEG-1안에서 정의 되었다.</p>
<p style="text-align: left;">피규어 1은 MPEG-1 계층 1과 2 코더의 높은 레벨의 개요를 보여준다. 입력 신호는 매우 균일하기 샘플링된 QMF filterbank에 의해 주파수에 걸쳐 분산되는 32개의 서브밴드 신호로 변환된다. The critically down sampled subband signals are grouped in a so called allocation frame (384 and 1152 subband samples for Layer I and II respectively). By means of Adaptive PCM, these allocation frames are subsequently quantized and coded into an MPEG-1 bitstream. At the decoder side, the bitstream is decoded into the subband samples which are subsequently fed into the inverse QMF filterbank.</p>
<p style="text-align: left;">Figure 1 shows a high level overview of the MPEG-1 Layers I and II coders. The input signal is transformed into 32 subband signals that are uniformly distributed over frequency by means of a critically sampled QMF filterbank. The critically down sampled subband signals are grouped in a so called allocation frame (384 and 1152 subband samples for Layer I and II respectively). By means of Adaptive PCM, these allocation frames are subsequently quantized and coded into an MPEG-1 bitstream. At the decoder side, the bitstream is decoded into the subband samples which are subsequently fed into the inverse QMF filterbank.</p>
<p style="text-align: left;"><img src="image/image004.gif" style="width: 570px; height: 250px;" /></p>
<p style="text-align: left;">Figure 1 – High level overview of MPEG-1 Layers I and II coder</p>
<p style="text-align: left;">Next to coding of mono and independent coding of stereo signals, also joint coding of stereo signals is supported by applying a technology called intensity stereo coding. Intensity coding exploits the property of the human auditory system that at high frequencies the perceived stereo image depends on intensity level differences.</p>
<p style="text-align: left;">A block diagram of the Layer 3 encoder algorithm is show in the following diagram:</p>
<p style="text-align: left;"><img src="image/image002.gif" style="width: 570px; height: 250px;" /></p>
<p style="text-align: left;">These blocks are described below.</p>
<h4 style="text-align: left;">Filter bank</h4>
<p style="text-align: left;">The filter bank used in MPEG Layer-3 is a hybrid filter bank which consists of a polyphase filter bank and a Modified Discrete Cosine Transform (MDCT). This hybrid form was chosen for reasons of  providing the same frame sizes as in Layer-1 and Layer-2.</p>
<h4 style="text-align: left;">Perceptual Model</h4>
<p style="text-align: left;">The perceptual model mainly determines the quality of a given encoder implementation. It uses either a separate filter bank or combines the calculation of energy values (for the masking calculations) and the main filter bank. The output of the perceptual model consists of values for the masking threshold or the allowed noise for each coder partition. If the quantization noise can be kept below the masking threshold, then the compression results should be indistinguishable from the original signal.</p>
<h4 style="text-align: left;">Joint Stereo</h4>
<p style="text-align: left;">Joint stereo coding takes advantage of the fact that both channels of a stereo channel pair contain far the same information. These stereophonic irrelevancies and redundancies are exploited to reduce the total bitrate. Joint stereo is used in cases where only low bitrates are available but stereo signals are desired.</p>
<h4 style="text-align: left;">Quantization and Coding</h4>
<p style="text-align: left;">A system of two nested iteration loops is the common solution for quantization and coding in a Layer-3 encoder.</p>
<p style="text-align: left;">Quantization is done via a power-law quantizer. In this way, larger values are automatically coded with less accuracy and some noise shaping is already built into the quantization process.</p>
<p style="text-align: left;">The quantized values are coded by Huffman coding. As a specific method for entropy coding, Huffman coding is lossless. This is called noiseless coding because no noise is added to the audio signal.</p>
<p style="text-align: left;">The process to find the optimum gain and scalefactors for a given block, bit-rate and output from the perceptual model is usually done by two nested iteration loops in an analysis-by-synthesis way:</p>
<h3 style="text-align: left;">Inner iteration loop (rate loop)</h3>
<p style="text-align: left;">The Huffman code tables assign shorter code words to (more frequent) smaller quantized values. If the number of bits resulting from the coding operation exceeds the number of bits available to code a given block of data, this can be corrected by adjusting the global gain to result in a larger quantization step size, leading to smaller quantized values. This operation is repeated with different quantization step sizes until the resulting bit demand for Huffman coding is small enough. The loop is called rate loop because it modifies the overall coder rate until it is small enough.</p>
<h3 style="text-align: left;"><em>Outer iteration loop (noise control/distortion loop)</em></h3>
<p style="text-align: left;">To shape the quantization noise according to the masking threshold, scalefactors are applied to each scalefactor band. The systems starts with a default factor of 1.0 for each band. If the quantization noise in a given band is found to exceed the masking threshold (allowed noise) as supplied by the perceptual model, the scalefactor for this band is adjusted to reduce the quantization noise. Since achieving a smaller quantization noise requires a larger number of quantization steps and thus a higher bitrate, the rate adjustment loop has to be repeated every time new scalefactors are used. In other words, the rate loop is nested within the noise control loop. The outer (noise control) loop is executed until the actual noise (computed from the difference of the original spectral values minus the quantized spectral values) is below the masking threshold for every scalefactor band (i.e. critical band). </p>
<p> </p>